{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03747d1-3c38-4fa6-b7c2-9b7b936799df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T06:13:17.181309Z",
     "iopub.status.busy": "2024-08-22T06:13:17.180901Z",
     "iopub.status.idle": "2024-08-22T06:13:17.192109Z",
     "shell.execute_reply": "2024-08-22T06:13:17.191599Z",
     "shell.execute_reply.started": "2024-08-22T06:13:17.181290Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "\n",
    "class JetDataset(Dataset):\n",
    "    \"\"\"JetDataset class for loading and processing jet data from HDF5 files.\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, subset_size=None, transform=None, config=None):\n",
    "        print(f\"Initializing JetDataset with file: {file_path}\")\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as hdf:\n",
    "            print(\"Loading features and subjets from HDF5 file\")\n",
    "            self.features = torch.tensor(hdf[\"particles/features\"][:], dtype=torch.float32)\n",
    "            self.subjets = [json.loads(subjet) for subjet in hdf[\"subjets\"][:]]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.config = config\n",
    "        print(f\"Raw dataset size: {len(self.subjets)} jets\")\n",
    "        print(f\"Feature shape: {self.features.shape}\")\n",
    "        \n",
    "        self.filter_good_jets()\n",
    "        \n",
    "        if subset_size is not None:\n",
    "            print(f\"Applying subset size: {subset_size}\")\n",
    "            self.features = self.features[:subset_size]\n",
    "            self.subjets = self.subjets[:subset_size]\n",
    "        \n",
    "        print(f\"Final dataset size: {len(self.subjets)} jets\")\n",
    "\n",
    "    def filter_good_jets(self):\n",
    "        \"\"\"\n",
    "        Filters jets to retain only those with a sufficient number of real subjets.\n",
    "        \"\"\"\n",
    "        print(\"Filtering good jets...\")\n",
    "        good_jets = []\n",
    "        good_features = []\n",
    "        \n",
    "        for i in range(len(self.subjets)):\n",
    "            num_real_subjets = self.get_num_real_subjets(self.subjets[i])\n",
    "            if num_real_subjets >= 10:\n",
    "                good_jets.append(self.subjets[i])\n",
    "                good_features.append(self.features[i])\n",
    "        \n",
    "        self.subjets = good_jets\n",
    "        self.features = torch.stack(good_features)\n",
    "        print(f\"Filtered to {len(self.subjets)} good jets\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_num_real_subjets(jet):\n",
    "        \"\"\"\n",
    "        Returns the number of real subjets in a given jet.\n",
    "        \"\"\"\n",
    "        return sum(1 for subjet in jet if subjet['features']['num_ptcls'] > 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the features and subjets for a given index and processes them.\n",
    "        \"\"\"\n",
    "        check_raw_data(self.subjets, jet_index=idx)  # Debug statement\n",
    "\n",
    "        print(f\"\\nFetching item {idx} from dataset\")\n",
    "        features = self.features[idx]\n",
    "        subjets = self.subjets[idx]\n",
    "\n",
    "        inspect_subjets(subjets)  # Debug statement\n",
    "\n",
    "        subjets, subjet_mask, particle_mask = self.process_subjets(subjets)\n",
    "        \n",
    "        check_processed_data(subjets)  # Debug statement\n",
    "\n",
    "        feature_names = ['pT', 'eta', 'phi']\n",
    "        print(\"Normalizing features\")\n",
    "        features = normalize_features(features, feature_names, self.config, jet_type='Jets')\n",
    "        \n",
    "        if self.transform:\n",
    "            print(\"Applying transform to features\")\n",
    "            features = self.transform(features)\n",
    "        \n",
    "        return features, subjets, subjet_mask, particle_mask\n",
    "\n",
    "    def process_subjets(self, subjets):\n",
    "        \"\"\"\n",
    "        Processes subjets to create tensor representations and masks.\n",
    "        \"\"\"\n",
    "        print(\"Processing subjets\")\n",
    "\n",
    "        max_len = max(len(subjet['indices']) for subjet in subjets)\n",
    "        print(f\"Max length of indices in subjets: {max_len}\")\n",
    "        subjet_tensors = []\n",
    "        subjet_mask = []\n",
    "        particle_mask = []\n",
    "        \n",
    "        for i, subjet in enumerate(subjets):\n",
    "            feature_tensors = [torch.tensor([subjet['features'][k]], dtype=torch.float32).expand(max_len) for k in ['pT', 'eta', 'phi', 'num_ptcls']]\n",
    "            features = torch.stack(feature_tensors, dim=0)\n",
    "            \n",
    "            is_empty = subjet['features']['num_ptcls'] == 0\n",
    "            subjet_mask.append(0 if is_empty else 1)\n",
    "            particle_mask.append([1 if i < len(subjet['indices']) else 0 for i in range(max_len)])\n",
    "\n",
    "            subjet_tensors.append(features)\n",
    "\n",
    "        subjets = torch.stack(subjet_tensors)\n",
    "        subjet_mask = torch.tensor(subjet_mask, dtype=torch.float32)\n",
    "        particle_mask = torch.tensor(particle_mask, dtype=torch.float32)\n",
    "        \n",
    "        print(f\"Final processed subjets shape: {subjets.shape}\")\n",
    "        print(f\"Final subjet mask shape: {subjet_mask.shape}\")\n",
    "        print(f\"Final particle mask shape: {particle_mask.shape}\")\n",
    "        \n",
    "        return subjets, subjet_mask, particle_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d8b43-96f9-4386-bf98-429d527c1ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
