{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da836fa1-cb29-44b5-8973-27698526d8aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T06:24:08.796366Z",
     "iopub.status.busy": "2024-08-22T06:24:08.796186Z",
     "iopub.status.idle": "2024-08-22T06:24:11.351983Z",
     "shell.execute_reply": "2024-08-22T06:24:11.351413Z",
     "shell.execute_reply.started": "2024-08-22T06:24:08.796352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in /opt/conda/lib/python3.11/site-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter\n",
    "import nbimporter\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from data_handling import JetDataset\n",
    "from model import JJEPA, Attention, MLP, Block, JetsTransformer, JetsTransformerPredictor\n",
    "from utils import create_random_masks, custom_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba41a339-8d1c-4865-b9e3-b61d3a2cc650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T06:24:11.353307Z",
     "iopub.status.busy": "2024-08-22T06:24:11.353009Z",
     "iopub.status.idle": "2024-08-22T06:24:11.358701Z",
     "shell.execute_reply": "2024-08-22T06:24:11.358211Z",
     "shell.execute_reply.started": "2024-08-22T06:24:11.353289Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(model, subjets, subjet_masks, particle_masks, optimizer, device, step):\n",
    "    print(f\"\\nStarting training step {step}\")\n",
    "    \n",
    "    # Debug Statement\n",
    "    check_processed_data(subjets)\n",
    "    \n",
    "    batch_size, num_subjets, num_features, subjet_length = subjets.size()\n",
    "    print(f\"Input shapes - Subjets: {subjets.shape}, Subjet masks: {subjet_masks.shape}, Particle masks: {particle_masks.shape}\")\n",
    "    \n",
    "    context_masks, target_masks = create_random_masks(batch_size, num_subjets, num_features, subjet_length)\n",
    "    print(f\"Context masks shape: {context_masks.shape}, Target masks shape: {target_masks.shape}\")\n",
    "    \n",
    "    context_masks = context_masks.to(device)\n",
    "    target_masks = target_masks.to(device)\n",
    "    subjet_masks = subjet_masks.to(device)\n",
    "    particle_masks = particle_masks.to(device)\n",
    "    \n",
    "    context_subjets = subjets * context_masks\n",
    "    target_subjets = subjets * target_masks\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(\"Forwarding through model\")\n",
    "    pred_repr, context_repr, target_repr = model(context_subjets, target_subjets)\n",
    "    \n",
    "    print(f\"Predicted representation shape: {pred_repr.shape}\")\n",
    "    print(f\"Target representation shape: {target_repr.shape}\")\n",
    "    \n",
    "    combined_mask = target_masks.to(device) * subjet_masks.unsqueeze(-1).unsqueeze(-1).expand_as(target_masks).to(device)\n",
    "    \n",
    "    pred_repr = pred_repr.to(device)\n",
    "    target_repr = target_repr.to(device)\n",
    "    \n",
    "    print(\"Calculating loss\")\n",
    "    loss = F.mse_loss(pred_repr * combined_mask, target_repr * combined_mask)\n",
    "    print(f\"Calculated loss: {loss.item()}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 500 == 0:\n",
    "        print_jet_details(pred_repr[0].cpu(), \"Predicted\")\n",
    "        visualize_predictions_vs_ground_truth(subjets[0].cpu(), pred_repr[0].cpu(), title=f\"Ground Truth vs Predictions (Step {step})\")\n",
    "        print(f\"Context representation shape: {context_repr.shape}\")\n",
    "        print(f\"Target representation shape: {target_repr.shape}\")\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a697f093-7c9c-4540-9f69-35b772ffcf82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T06:24:11.359309Z",
     "iopub.status.busy": "2024-08-22T06:24:11.359186Z",
     "iopub.status.idle": "2024-08-22T06:24:11.389586Z",
     "shell.execute_reply": "2024-08-22T06:24:11.389105Z",
     "shell.execute_reply.started": "2024-08-22T06:24:11.359297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main program\n",
      "Using device: cuda\n",
      "Loading dataset\n",
      "Initializing JetDataset with file: ../data/val/val_20_30.h5\n",
      "Error loading dataset: [Errno 2] Unable to synchronously open file (unable to open file: name = '../data/val/val_20_30.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Creating DataLoader\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating DataLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcustom_collate_fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m JJEPA(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m240\u001b[39m, embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, mlp_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting main program\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    with open('config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        \n",
    "    try:\n",
    "        print(\"Loading dataset\")\n",
    "        train_dataset = JetDataset(\"../data/val/val_20_30.h5\", subset_size=1000, config=config)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "    print(\"Creating DataLoader\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    print(\"Initializing model\")\n",
    "    model = JJEPA(input_dim=240, embed_dim=512, depth=12, num_heads=8, mlp_ratio=4.0, dropout=0.1).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.04)\n",
    "\n",
    "    num_epochs = 10\n",
    "    train_losses = []\n",
    "    \n",
    "    print(f\"Starting training for {num_epochs} epochs\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True, position=0)\n",
    "    \n",
    "        for step, (features, subjets, subjet_masks, particle_masks) in enumerate(train_loader):\n",
    "            features = features.to(device)\n",
    "            subjets = subjets.to(device)\n",
    "            subjet_masks = subjet_masks.to(device)\n",
    "            particle_masks = particle_masks.to(device)\n",
    "            \n",
    "            loss = train_step(model, subjets, subjet_masks, particle_masks, optimizer, device, step)\n",
    "            total_loss += loss\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss)\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(f\"\\nEpoch {epoch+1}, Step {step}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        progress_bar.close()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed\")\n",
    "    print(\"Visualizing training loss\")\n",
    "    visualize_training_loss(train_losses)\n",
    "\n",
    "    print(\"Saving model\")\n",
    "    torch.save(model.state_dict(), 'ijepa_model.pth')\n",
    "\n",
    "    print(\"Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7d992-bf74-406c-b6e2-3bb7f6308c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
