{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b524da-7f65-41c4-8e08-f5fb82feacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size (32)\n",
    "# Number of subjets (20)\n",
    "# Number of Feature (8)\n",
    "# subject length (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f0579e-75db-4461-83ea-83f8de825699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary modules imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# HDF5 handling\n",
    "import h5py\n",
    "\n",
    "print(\"All necessary modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d520d78-bce3-4ec2-ac35-24f15dd8cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetDataset(Dataset):\n",
    "    def __init__(self, file_path, subset_size=None, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the JetDataset with data from an HDF5 file.\n",
    "        \n",
    "        Parameters:\n",
    "        - file_path (str): Path to the HDF5 file containing the dataset.\n",
    "        - subset_size (int, optional): Number of samples to use from the dataset.\n",
    "        - transform (callable, optional): Transform to apply to the features.\n",
    "        \"\"\"\n",
    "        print(f\"Initializing JetDataset with file: {file_path}\")\n",
    "        \n",
    "        # Load data from HDF5 file\n",
    "        with h5py.File(file_path, 'r') as hdf:\n",
    "            self.features = torch.tensor(hdf[\"particles/features\"][:], dtype=torch.float32)\n",
    "            self.subjets = [json.loads(subjet) for subjet in hdf[\"subjets\"][:]]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Raw dataset size: {len(self.subjets)} jets\")\n",
    "        print(f\"Feature shape: {self.features.shape}\")\n",
    "        \n",
    "        # Filter jets with at least 10 real subjets\n",
    "        self.filter_good_jets()\n",
    "        \n",
    "        if subset_size is not None:\n",
    "            print(f\"Applying subset size: {subset_size}\")\n",
    "            self.features = self.features[:subset_size]\n",
    "            self.subjets = self.subjets[:subset_size]\n",
    "        \n",
    "        print(f\"Final dataset size: {len(self.subjets)} jets\")\n",
    "\n",
    "    def filter_good_jets(self):\n",
    "        \"\"\"\n",
    "        Filters the jets to keep only those with at least 10 real subjets.\n",
    "        \"\"\"\n",
    "        print(\"Filtering good jets...\")\n",
    "        good_jets = []\n",
    "        good_features = []\n",
    "        \n",
    "        for i in range(len(self.subjets)):\n",
    "            num_real_subjets = self.get_num_real_subjets(self.subjets[i])\n",
    "            if num_real_subjets >= 10:\n",
    "                good_jets.append(self.subjets[i])\n",
    "                good_features.append(self.features[i])\n",
    "\n",
    "            # Uncomment the lines below to print progress every 1000 jets\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f\"Processed {i} jets, found {len(good_jets)} good jets\")\n",
    "        \n",
    "        self.subjets = good_jets\n",
    "        self.features = torch.stack(good_features)\n",
    "        print(f\"Filtered to {len(self.subjets)} good jets\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_num_real_subjets(jet):\n",
    "        \"\"\"\n",
    "        Counts and returns the number of real subjets in a given jet.\n",
    "        \n",
    "        Parameters:\n",
    "        - jet (list): A list of subjets where each subjet is a dictionary.\n",
    "        \n",
    "        Returns:\n",
    "        - int: Number of real subjets (those with num_ptcls > 0).\n",
    "        \"\"\"\n",
    "        return sum(1 for subjet in jet if subjet['features']['num_ptcls'] > 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of jets in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        - int: Number of jets.\n",
    "        \"\"\"\n",
    "        return len(self.subjets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the features and subjets for a given index and processes them.\n",
    "        \n",
    "        Parameters:\n",
    "        - idx (int): Index of the jet to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "        - tuple: (features, subjets, subjet_mask, particle_mask)\n",
    "          where `features` is the normalized feature tensor,\n",
    "          `subjets` is the processed subjets tensor,\n",
    "          `subjet_mask` is the mask for subjets,\n",
    "          and `particle_mask` is the mask for particles.\n",
    "        \"\"\"\n",
    "        features = self.features[idx]\n",
    "        subjets = self.subjets[idx]\n",
    "        subjets, subjet_mask, particle_mask = self.process_subjets(subjets)\n",
    "        \n",
    "        feature_names = ['pT', 'eta', 'phi']\n",
    "        features = normalize_features(features, feature_names, config, jet_type='Jets')\n",
    "        \n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"Getting item {idx}\")\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Subjets shape: {subjets.shape}\")\n",
    "            print(f\"Subjet mask shape: {subjet_mask.shape}\")\n",
    "            print(f\"Particle mask shape: {particle_mask.shape}\")\n",
    "            print(f\"Number of non-empty subjets: {subjet_mask.sum().item()}\")\n",
    "            print(f\"Number of non-empty particles: {particle_mask.sum().item()}\")\n",
    "\n",
    "        return features, subjets, subjet_mask, particle_mask\n",
    "\n",
    "    def process_subjets(self, subjets):\n",
    "        \"\"\"\n",
    "        Processes subjets to create tensor representations and masks.\n",
    "        \n",
    "        Parameters:\n",
    "        - subjets (list): List of subjets where each subjet is a dictionary.\n",
    "        \n",
    "        Returns:\n",
    "        - tuple: (subjets, subjet_mask, particle_mask)\n",
    "          where `subjets` is the tensor representation of subjets,\n",
    "          `subjet_mask` is the mask for subjets,\n",
    "          and `particle_mask` is the mask for particles.\n",
    "        \"\"\"\n",
    "        if isinstance(subjets, torch.Tensor):\n",
    "            subjets = subjets.tolist()\n",
    "\n",
    "        if isinstance(subjets[0], list):\n",
    "            subjets = [{'features': {'pT': s[0], 'eta': s[1], 'phi': s[2], 'num_ptcls': s[3]}, 'indices': s[4:]} for s in subjets]\n",
    "\n",
    "        max_len = max(len(subjet['indices']) for subjet in subjets)\n",
    "        subjet_tensors = []\n",
    "        subjet_mask = []\n",
    "        particle_mask = []\n",
    "        \n",
    "        for i, subjet in enumerate(subjets):\n",
    "            feature_tensors = [torch.tensor([subjet['features'][k]], dtype=torch.float32).expand(max_len) for k in ['pT', 'eta', 'phi', 'num_ptcls']]\n",
    "            features = torch.stack(feature_tensors, dim=0)\n",
    "            \n",
    "            print(f\"Subjet feature tensors shape after adjustment: {features.shape}\")\n",
    "            indices = torch.tensor(subjet['indices'], dtype=torch.float32).unsqueeze(0).expand(features.size(0), -1)\n",
    "\n",
    "            if indices.shape[1] < max_len:\n",
    "                pad_len = max_len - indices.shape[1]\n",
    "                indices = torch.nn.functional.pad(indices, (0, pad_len), 'constant', -1)\n",
    "\n",
    "            combined = torch.cat([features, indices], dim=0)\n",
    "            subjet_tensors.append(combined)\n",
    "            \n",
    "            is_empty = subjet['features']['num_ptcls'] == 0\n",
    "            subjet_mask.append(0 if is_empty else 1)\n",
    "            particle_mask.append([1 if i < len(subjet['indices']) else 0 for i in range(max_len)])\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processed subjet {i}\")\n",
    "                print(f\"Subjet features shape: {features.shape}\")\n",
    "                print(f\"Subjet indices shape: {indices.shape}\")\n",
    "                print(f\"Is empty: {is_empty}\")\n",
    "\n",
    "        subjets = torch.stack(subjet_tensors)\n",
    "        subjet_mask = torch.tensor(subjet_mask, dtype=torch.float32)\n",
    "        particle_mask = torch.tensor(particle_mask, dtype=torch.float32)\n",
    "        \n",
    "        print(f\"Processed subjets shape: {subjets.shape}\")\n",
    "        print(f\"Subjet mask shape: {subjet_mask.shape}\")\n",
    "        print(f\"Particle mask shape: {particle_mask.shape}\")\n",
    "        \n",
    "        return subjets, subjet_mask, particle_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63dfe970-5262-4948-ad41-5c443c10f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for DataLoader to handle variable-sized subjets and particles.\n",
    "    \n",
    "    Parameters:\n",
    "    - batch (list): List of tuples where each tuple contains (features, subjets, subjet_mask, particle_mask).\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (features, subjets, subjet_masks, particle_masks) where each element is a padded tensor.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting custom_collate_fn ---\")\n",
    "    \n",
    "    # Unzip the batch to separate features, subjets, subjet_masks, and particle_masks\n",
    "    features, subjets, subjet_masks, particle_masks = zip(*batch)\n",
    "    \n",
    "    # Stack features along a new dimension\n",
    "    features = torch.stack(features)\n",
    "    print(f\"Features shape after stacking: {features.shape}\")\n",
    "    \n",
    "    # Determine the maximum dimensions for padding\n",
    "    max_subjets = max(s.size(0) for s in subjets)\n",
    "    max_subjet_features = max(s.size(1) for s in subjets)\n",
    "    max_subjet_length = max(s.size(2) for s in subjets)\n",
    "    \n",
    "    print(f\"Max subjets: {max_subjets}\")\n",
    "    print(f\"Max subjet features: {max_subjet_features}\")\n",
    "    print(f\"Max subjet length: {max_subjet_length}\")\n",
    "    \n",
    "    padded_subjets = []\n",
    "    padded_subjet_masks = []\n",
    "    padded_particle_masks = []\n",
    "    \n",
    "    # Pad each element in the batch to match the maximum dimensions\n",
    "    for i, (s, sm, pm) in enumerate(zip(subjets, subjet_masks, particle_masks)):\n",
    "        print(f\"\\nProcessing batch item {i+1}/{len(batch)}:\")\n",
    "        print(f\"Original subjets shape: {s.shape}\")\n",
    "        print(f\"Original subjet mask shape: {sm.shape}\")\n",
    "        print(f\"Original particle mask shape: {pm.shape}\")\n",
    "\n",
    "        print(f\"size of 0 : {s.size(0)}\")\n",
    "        print(f\"size of 1 : {s.size(1)}\")\n",
    "        print(f\"size of 2 : {s.size(2)}\")\n",
    "        \n",
    "        pad_subjets = max_subjets - s.size(0)\n",
    "        pad_features = max_subjet_features - s.size(1)\n",
    "        pad_length = max_subjet_length - s.size(2)\n",
    "        \n",
    "        print(f\"Padding required - Subjets: {pad_subjets}, Features: {pad_features}, Length: {pad_length}\")\n",
    "\n",
    "        if(pad_subjets > 0 or pad_features > 0 or pad_length > 0):\n",
    "            # Pad the subjets tensor\n",
    "            padded_s = F.pad(s, (0, pad_length, 0, pad_features, 0, pad_subjets), \"constant\", 0)\n",
    "            padded_subjets.append(padded_s)\n",
    "            \n",
    "            # Pad the subjet masks tensor\n",
    "            padded_sm = F.pad(sm, (0, pad_subjets), \"constant\", 0)\n",
    "            padded_subjet_masks.append(padded_sm)\n",
    "            \n",
    "            # Pad the particle masks tensor\n",
    "            padded_pm = F.pad(pm, (0, pad_length, 0, pad_subjets), \"constant\", 0)\n",
    "            padded_particle_masks.append(padded_pm)\n",
    "        \n",
    "        \n",
    "            print(f\"Padded subjets shape: {padded_s.shape}\")\n",
    "            print(f\"Padded subjet mask shape: {padded_sm.shape}\")\n",
    "            print(f\"Padded particle mask shape: {padded_pm.shape}\")\n",
    "    \n",
    "    # Stack the padded tensors\n",
    "    subjets = torch.stack(padded_subjets)\n",
    "    subjet_masks = torch.stack(padded_subjet_masks)\n",
    "    particle_masks = torch.stack(padded_particle_masks)\n",
    "    \n",
    "    print(f\"\\nFinal stacked subjets shape: {subjets.shape}\")\n",
    "    print(f\"Final stacked subjet masks shape: {subjet_masks.shape}\")\n",
    "    print(f\"Final stacked particle masks shape: {particle_masks.shape}\")\n",
    "    \n",
    "    print(\"--- End of custom_collate_fn ---\\n\")\n",
    "    \n",
    "    return features, subjets, subjet_masks, particle_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eda5aef3-c18f-47f4-9bdb-f4b639fc77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class IJEPA(nn.Module):\n",
    "    \"\"\"\n",
    "    IJEPA model class that uses a transformer encoder for context and target representations\n",
    "    and predicts representations for masked parts of the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, embed_dim, depth, num_heads, mlp_ratio, dropout=0.1, use_predictor=True):\n",
    "        \"\"\"\n",
    "        Initializes the IJEPA model.\n",
    "        \n",
    "        Parameters:\n",
    "        - input_dim (int): The dimension of the input features.\n",
    "        - embed_dim (int): The dimension of the embedding space.\n",
    "        - depth (int): The number of layers in the transformer encoder.\n",
    "        - num_heads (int): The number of attention heads in the transformer encoder.\n",
    "        - mlp_ratio (float): The ratio of the hidden dimension in the MLP layer relative to the embedding dimension.\n",
    "        - dropout (float): The dropout rate.\n",
    "        - max_seq_len (int): The maximum sequence length for positional embeddings.\n",
    "        - use_predictor (bool): Whether to use the predictor module.\n",
    "        \"\"\"\n",
    "        super(J_JepaBase, self).__init__()\n",
    "        self.use_predictor = use_predictor\n",
    "        \n",
    "        print(f\"Initializing IJEPA with input_dim={input_dim}, embed_dim={embed_dim}, use_predictor={use_predictor}\")\n",
    "\n",
    "        # TODO: Positional embedding\n",
    "        \n",
    "        # Transformer encoders for context and target\n",
    "        self.context_encoder = self.create_encoder(embed_dim, depth, num_heads, mlp_ratio, dropout)\n",
    "        self.target_encoder = self.create_encoder(embed_dim, depth, num_heads, mlp_ratio, dropout)\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        if use_predictor:\n",
    "            # Predictor MLP to transform the context representations to match the input dimension\n",
    "            self.predictor = nn.Sequential(\n",
    "                nn.Linear(embed_dim, embed_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(embed_dim, input_dim)  # Ensure the output dimension matches the input dimension\n",
    "            )\n",
    "\n",
    "    def create_encoder(self, embed_dim, depth, num_heads, mlp_ratio, dropout):\n",
    "        \"\"\"\n",
    "        Creates a transformer encoder.\n",
    "        \n",
    "        Parameters:\n",
    "        - embed_dim (int): The dimension of the embedding space.\n",
    "        - depth (int): The number of layers in the transformer encoder.\n",
    "        - num_heads (int): The number of attention heads in the transformer encoder.\n",
    "        - mlp_ratio (float): The ratio of the hidden dimension in the MLP layer relative to the embedding dimension.\n",
    "        - dropout (float): The dropout rate.\n",
    "        \n",
    "        Returns:\n",
    "        - nn.TransformerEncoder: A transformer encoder.\n",
    "        \"\"\"\n",
    "        return nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, \n",
    "                                       dim_feedforward=int(embed_dim * mlp_ratio), \n",
    "                                       dropout=dropout),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "    def forward(self, context, target):\n",
    "        \"\"\"\n",
    "        Forward pass of the IJEPA model.\n",
    "        \n",
    "        Parameters:\n",
    "        - context (torch.Tensor): The context input tensor.\n",
    "        - target (torch.Tensor): The target input tensor.\n",
    "        \n",
    "        Returns:\n",
    "        - pred_repr (torch.Tensor or None): The predicted representations for the masked parts (if use_predictor is True).\n",
    "        - target_repr (torch.Tensor): The encoded target representations.\n",
    "        - context_repr_shape (torch.Size): The shape of the context representations.\n",
    "        - target_repr_shape (torch.Size): The shape of the target representations.\n",
    "        \"\"\"\n",
    "        print(\"Starting IJEPA forward pass\")\n",
    "        batch_size, num_subjets, num_features, subjet_length = context.size()\n",
    "        \n",
    "        print(f\"Input context shape: {context.shape}\")\n",
    "        print(f\"Input target shape: {target.shape}\")\n",
    "        \n",
    "        # Flatten the context and target tensors\n",
    "        context = context.view(batch_size, num_subjets, -1)\n",
    "        target = target.view(batch_size, num_subjets, -1)\n",
    "        \n",
    "        print(f\"Reshaped context shape: {context.shape}\")\n",
    "        print(f\"Reshaped target shape: {target.shape}\")\n",
    "        \n",
    "        # Apply the embedding layer\n",
    "        context_emb = self.embedding(context)\n",
    "        target_emb = self.embedding(target)\n",
    "        \n",
    "        print(f\"Embedded context shape: {context.shape}\")\n",
    "        print(f\"Embedded target shape: {target.shape}\")\n",
    "        \n",
    "        # TODO: Add positional embeddings\n",
    "        \n",
    "        print(\"Applying context encoder\")\n",
    "        # Encode the context representations\n",
    "        context_repr = self.context_encoder(context_emb.transpose(0, 1)).transpose(0,1)\n",
    "        print(\"Applying target encoder\")\n",
    "        target_repr = self.target_encoder(target_emb.transpose(0, 1)).transpose(0, 1)\n",
    "        \n",
    "        print(f\"Context encoder output shape: {context_repr.shape}\")\n",
    "        print(f\"Target encoder output shape: {target_repr.shape}\")\n",
    "        \n",
    "        if self.use_predictor:\n",
    "            print(\"Applying predictor\")\n",
    "            # Predict the representations for the masked parts\n",
    "            pred_repr = self.predictor(context_repr)\n",
    "            return pred_repr, context_repr, target_repr\n",
    "            \n",
    "        \n",
    "        print(f\"Final predicted representation shape: {pred_repr.shape if pred_repr is not None else 'N/A'}\")\n",
    "        print(f\"Final target representation shape: {target_repr.shape}\")\n",
    "        \n",
    "        return pred_repr, target_repr, context_repr.shape, target_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f3707ef-7104-4374-ad7c-e9a7a47da5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, subjets, subjet_masks, particle_masks, optimizer, device, step):\n",
    "    \"\"\"\n",
    "    Performs a single training step for the IJEPA model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (nn.Module): The IJEPA model.\n",
    "    - subjets (torch.Tensor): The input subjets tensor.\n",
    "    - subjet_masks (torch.Tensor): The mask tensor for the subjets.\n",
    "    - particle_masks (torch.Tensor): The mask tensor for the particles.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer.\n",
    "    - device (torch.device): The device to run the training on (CPU or GPU).\n",
    "    - step (int): The current training step number.\n",
    "    \n",
    "    Returns:\n",
    "    - loss.item() (float): The loss value for the current training step.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nStarting training step {step}\")\n",
    "    batch_size, num_subjets, num_features, subjet_length = subjets.size()\n",
    "    print(f\"Input shapes - Subjets: {subjets.shape}, Subjet masks: {subjet_masks.shape}, Particle masks: {particle_masks.shape}\")\n",
    "    \n",
    "    # Create random masks for context and target\n",
    "    context_masks, target_masks = create_random_masks(batch_size, num_subjets, num_features, subjet_length)\n",
    "    \n",
    "    # Move masks and inputs to the appropriate device\n",
    "    context_masks = context_masks.to(device)\n",
    "    target_masks = target_masks.to(device)\n",
    "    subjet_masks = subjet_masks.to(device)\n",
    "    particle_masks = particle_masks.to(device)\n",
    "    \n",
    "    print(f\"Mask shapes - Context: {context_masks.shape}, Target: {target_masks.shape}\")\n",
    "    \n",
    "    # Apply masks to the input subjets\n",
    "    context_subjets = subjets * context_masks\n",
    "    target_subjets = subjets * target_masks\n",
    "    \n",
    "    print(f\"Context subjets shape: {context_subjets.shape}\")\n",
    "    print(f\"Target subjets shape: {target_subjets.shape}\")\n",
    "    \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(\"Forwarding through model\")\n",
    "    # Forward pass through the model\n",
    "    pred_repr, target_repr, context_repr_shape, target_repr_shape = model(context_subjets, target_subjets)  # Use masked subjets as target\n",
    "    \n",
    "    print(f\"Predicted representation shape: {pred_repr.shape}\")\n",
    "    print(f\"Target representation shape: {target_repr.shape}\")\n",
    "    \n",
    "    # Apply masks to the loss calculation\n",
    "    combined_mask = target_masks.to(device) * subjet_masks.unsqueeze(-1).unsqueeze(-1).expand_as(target_masks).to(device)\n",
    "    \n",
    "    # Ensure `pred_repr` and `target_repr` are on the same device\n",
    "    pred_repr = pred_repr.to(device)\n",
    "    target_repr = target_repr.to(device)\n",
    "    \n",
    "    # Compute the masked mean squared error loss\n",
    "    loss = F.mse_loss(pred_repr * combined_mask, target_repr * combined_mask)\n",
    "    print(f\"Calculated loss: {loss.item()}\")\n",
    "    \n",
    "    # Backward pass and optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print and visualize predictions every 500 steps\n",
    "    if step % 500 == 0:\n",
    "        print_jet_details(pred_repr[0].cpu(), \"Predicted\")\n",
    "        visualize_predictions_vs_ground_truth(subjets[0].cpu(), pred_repr[0].cpu(), title=f\"Ground Truth vs Predictions (Step {step})\")\n",
    "        print(f\"Context representation shape: {context_repr_shape}\")\n",
    "        print(f\"Target representation shape: {target_repr_shape}\")\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50d6b2c3-8e06-47f1-bdf0-90f99484c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_masks(batch_size, num_subjets, num_features, subjet_length, context_scale=0.7):\n",
    "    \"\"\"\n",
    "    Creates random masks for context and target subjets.\n",
    "    \n",
    "    Parameters:\n",
    "    - batch_size (int): Number of samples in a batch.\n",
    "    - num_subjets (int): Number of subjets in each sample.\n",
    "    - num_features (int): Number of features in each subjet.\n",
    "    - subjet_length (int): Length of each subjet.\n",
    "    - context_scale (float): Proportion of subjets to be used as context.\n",
    "    \n",
    "    Returns:\n",
    "    - context_masks (torch.Tensor): Tensor of context masks.\n",
    "    - target_masks (torch.Tensor): Tensor of target masks.\n",
    "    \"\"\"\n",
    "    print(f\"Creating random masks with batch_size={batch_size}, num_subjets={num_subjets}\")\n",
    "    context_masks = []\n",
    "    target_masks = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Randomly permute indices of subjets\n",
    "        indices = torch.randperm(num_subjets)\n",
    "        context_size = int(num_subjets * context_scale)\n",
    "        context_indices = indices[:context_size]\n",
    "        target_indices = indices[context_size:]\n",
    "\n",
    "        # Initialize masks with zeros\n",
    "        context_mask = torch.zeros(num_subjets, num_features, subjet_length)\n",
    "        target_mask = torch.zeros(num_subjets, num_features, subjet_length)\n",
    "\n",
    "        # Set mask values for context and target\n",
    "        context_mask[context_indices] = 1\n",
    "        target_mask[target_indices] = 1\n",
    "\n",
    "        context_masks.append(context_mask)\n",
    "        target_masks.append(target_mask)\n",
    "\n",
    "        if i == 0:\n",
    "            print(f\"Sample context mask shape: {context_mask.shape}\")\n",
    "            print(f\"Sample target mask shape: {target_mask.shape}\")\n",
    "\n",
    "    return torch.stack(context_masks), torch.stack(target_masks)\n",
    "\n",
    "# def normalize_features(features):\n",
    "#     \"\"\"\n",
    "#     Normalizes the features tensor.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - features (torch.Tensor): Input features tensor.\n",
    "    \n",
    "#     Returns:\n",
    "#     - normalized (torch.Tensor): Normalized features tensor.\n",
    "#     \"\"\"\n",
    "#     print(\"Normalizing features\")\n",
    "#     mean = features.mean(dim=0, keepdim=True)\n",
    "#     std = features.std(dim=0, keepdim=True)\n",
    "#     std[std == 0] = 1e-8  # Prevent division by zero\n",
    "#     normalized = (features - mean) / std\n",
    "#     print(f\"Normalized features shape: {normalized.shape}\")\n",
    "#     return normalized\n",
    "\n",
    "# load normalize config\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "def normalize_features(features, feature_names, config, jet_type=\"Jets\"):\n",
    "    \"\"\"\n",
    "    Normalize the input features using methods specified in the YAML configuration file.\n",
    "    \n",
    "    Parameters:\n",
    "    - features (Tensor): Input features of shape (num_particles, num_features).\n",
    "    - feature_names (list of str): List of feature names corresponding to the columns in `features`.\n",
    "    - config (dict): Configuration dictionary loaded from the YAML file.\n",
    "    - jet_type (str): The type of jet ('Jets' or 'Subjets') for which normalization is applied.\n",
    "    \n",
    "    Returns:\n",
    "    - Tensor: Normalized features.\n",
    "    \"\"\"\n",
    "\n",
    "    normalized_features = features.clone()\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        method = config[\"INPUTS\"][\"SEQUENTIAL\"][jet_type].get(feature_name, \"none\")\n",
    "        print(f\"Normalizing feature'{feature_name}' with method '{method}'\")\n",
    "\n",
    "        if method == \"normalize\":\n",
    "            mean = features[:, i].mean()\n",
    "            std = features[:, i].std()\n",
    "            std = std if std > 1e-8 else 1.0  #to prevent division by zero\n",
    "            normalized_features[:, 1] = (features[:, i] - mean )/std\n",
    "        elif method == \"log_normalize\":\n",
    "            normalized_features[:,i] =  torch.log1p(features[:, i])\n",
    "\n",
    "\n",
    "    return normalized_features\n",
    "\n",
    "def print_jet_details(jet, name):\n",
    "    \"\"\"\n",
    "    Prints details of the given jet tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - jet (torch.Tensor): Input jet tensor.\n",
    "    - name (str): Name of the jet for identification.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{name} Jet Details:\")\n",
    "    print(f\"Shape: {jet.shape}\")\n",
    "    print(f\"Non-zero elements: {torch.count_nonzero(jet)}\")\n",
    "    print(\"\\nFirst few elements:\")\n",
    "    print(jet[0, :5, :5])\n",
    "\n",
    "def visualize_jet(subjets, mask=None, title=\"Jet Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes the subjets in a scatter plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - subjets (torch.Tensor): Tensor of subjets.\n",
    "    - mask (torch.Tensor, optional): Mask tensor for filtering subjets.\n",
    "    - title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    valid_points = False\n",
    "    for i in range(subjets.size(0)):\n",
    "        if mask is None or mask[i].any():\n",
    "            eta = subjets[i, 1, 0].item()\n",
    "            phi = subjets[i, 2, 0].item()\n",
    "            pT = subjets[i, 0, 0].item()\n",
    "            if pT > 0:\n",
    "                ax.scatter(eta, phi, s=pT * 5, alpha=0.7)\n",
    "                valid_points = True\n",
    "    \n",
    "    ax.set_xlabel('Eta')\n",
    "    ax.set_ylabel('Phi')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if valid_points and ax.collections:\n",
    "        plt.colorbar(ax.collections[0], label='pT')\n",
    "    else:\n",
    "        print(f\"No valid points to display for {title}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def visualize_context_and_targets(subjets, context_mask, target_mask):\n",
    "    \"\"\"\n",
    "    Visualizes context and target subjets in a scatter plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - subjets (torch.Tensor): Tensor of subjets.\n",
    "    - context_mask (torch.Tensor): Mask tensor for context subjets.\n",
    "    - target_mask (torch.Tensor): Mask tensor for target subjets.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "    def scatter_jet(ax, jet_data, mask, title):\n",
    "        for i in range(jet_data.size(0)):\n",
    "            if mask[i, 0, 0].item() > 0:  # Check only the first element of each subjet\n",
    "                eta = jet_data[i, 1, 0].item()\n",
    "                phi = jet_data[i, 2, 0].item()\n",
    "                pT = jet_data[i, 0, 0].item()\n",
    "                if pT > 0:\n",
    "                    scatter = ax.scatter(eta, phi, s=pT * 5, alpha=0.7)\n",
    "        ax.set_xlabel('Eta')\n",
    "        ax.set_ylabel('Phi')\n",
    "        ax.set_title(title)\n",
    "        if ax.collections:\n",
    "            plt.colorbar(ax.collections[0], ax=ax, label='pT')\n",
    "\n",
    "    scatter_jet(ax1, subjets, torch.ones_like(context_mask), \"Full Jet\")\n",
    "    scatter_jet(ax2, subjets, context_mask, \"Context Subjets\")\n",
    "    scatter_jet(ax3, subjets, target_mask, \"Target Subjets\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions_vs_ground_truth(subjets, pred_repr, title=\"Ground Truth vs Predictions\"):\n",
    "    \"\"\"\n",
    "    Visualizes ground truth and predicted subjets in a scatter plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - subjets (torch.Tensor): Ground truth subjets tensor.\n",
    "    - pred_repr (torch.Tensor): Predicted subjets tensor.\n",
    "    - title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "    def scatter_jet(ax, subjets, title):\n",
    "        valid_points = False\n",
    "        for i in range(subjets.size(0)):\n",
    "            eta = subjets[i, 1, 0].item()\n",
    "            phi = subjets[i, 2, 0].item()\n",
    "            pT = subjets[i, 0, 0].item()\n",
    "            if pT > 0:\n",
    "                ax.scatter(eta, phi, s=pT * 5, alpha=0.7)\n",
    "                valid_points = True\n",
    "        ax.set_xlabel('Eta')\n",
    "        ax.set_ylabel('Phi')\n",
    "        ax.set_title(title)\n",
    "        if valid_points and ax.collections:\n",
    "            plt.colorbar(ax.collections[0], label='pT')\n",
    "\n",
    "    scatter_jet(ax1, subjets, \"Ground Truth\")\n",
    "    scatter_jet(ax2, pred_repr, \"Predictions\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_training_loss(train_losses):\n",
    "    \"\"\"\n",
    "    Plots the training loss over epochs.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_losses (list of float): List of training loss values.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_sample_prediction(train_loader, model, device, step=0):\n",
    "    \"\"\"\n",
    "    Visualizes a sample prediction after training.\n",
    "    \n",
    "    Parameters:\n",
    "    train_loader (DataLoader): DataLoader for the training data.\n",
    "    model (IJEPA): The trained model.\n",
    "    device (torch.device): Device to run the model on (CPU or GPU).\n",
    "    step (int): Step number for labeling the visualization (default: 0).\n",
    "    \"\"\"\n",
    "    # Print a message indicating the start of sample prediction visualization\n",
    "    print(\"Visualizing sample prediction\")\n",
    "\n",
    "    # Set the model to evaluation mode (disables dropout, batch normalization, etc.)\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        # Get the next batch of data from the train_loader\n",
    "        sample_batch = next(iter(train_loader))\n",
    "\n",
    "        # Unpack the batch to get subjets, subjet masks, and particle masks\n",
    "        _, sample_subjets, sample_subjet_masks, sample_particle_masks = sample_batch\n",
    "\n",
    "        # Move the tensors to the specified device (CPU or GPU)\n",
    "        sample_subjets = sample_subjets.to(device)\n",
    "        sample_subjet_masks = sample_subjet_masks.to(device)\n",
    "        sample_particle_masks = sample_particle_masks.to(device)\n",
    "\n",
    "        # Get the dimensions of the sample_subjets tensor\n",
    "        batch_size, num_subjets, num_features, subjet_length = sample_subjets.size()\n",
    "\n",
    "        # Create random context and target masks\n",
    "        context_masks, target_masks = create_random_masks(batch_size, num_subjets, num_features, subjet_length)\n",
    "\n",
    "        # Move the masks to the specified device (CPU or GPU)\n",
    "        context_masks = context_masks.to(device)\n",
    "        target_masks = target_masks.to(device)\n",
    "\n",
    "        # Apply the masks to the sample subjets to create context and target subjets\n",
    "        context_subjets = sample_subjets * context_masks\n",
    "        target_subjets = sample_subjets * target_masks\n",
    "\n",
    "        # Feed the context and target subjets into the model to get the predicted and target representations\n",
    "        pred_repr, target_repr, context_repr_shape, target_repr_shape = model(context_subjets, target_subjets)\n",
    "\n",
    "        # Print the shapes of the final context and target representations\n",
    "        print(f\"Final context representation shape: {context_repr_shape}\")\n",
    "        print(f\"Final target representation shape: {target_repr_shape}\")\n",
    "\n",
    "        # Visualize the ground truth vs predictions for the first item in the batch\n",
    "        visualize_predictions_vs_ground_truth(sample_subjets[0].cpu(), pred_repr[0].cpu(), title=f\"Final Model: Ground Truth vs Predictions (Step {step})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064b624b-fffa-41aa-900a-c57a368350cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T00:04:33.544803Z",
     "iopub.status.busy": "2024-08-18T00:04:33.544282Z",
     "iopub.status.idle": "2024-08-18T00:05:10.657490Z",
     "shell.execute_reply": "2024-08-18T00:05:10.656688Z",
     "shell.execute_reply.started": "2024-08-18T00:04:33.544785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main program\n",
      "Using device: cuda\n",
      "Loading dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 183\u001b[0m, in \u001b[0;36mJetDataset.__init__\u001b[0;34m(self, file_path, subset_size)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(hdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticles/features\u001b[39m\u001b[38;5;124m\"\u001b[39m][:], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubjets \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubjet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubjets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_good_jets()\n",
      "Cell \u001b[0;32mIn[3], line 183\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(hdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticles/features\u001b[39m\u001b[38;5;124m\"\u001b[39m][:], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubjets \u001b[38;5;241m=\u001b[39m [\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjet\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m subjet \u001b[38;5;129;01min\u001b[39;00m hdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjets\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_good_jets()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mJetDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/val/val_20_30.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use only 1000 samples    \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 181\u001b[0m, in \u001b[0;36mJetDataset.__init__\u001b[0;34m(self, file_path, subset_size)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path, subset_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhdf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparticles/features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubjets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubjet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubjets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/h5py/_hl/files.py:601\u001b[0m, in \u001b[0;36mFile.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid:\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting main program\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "        \n",
    "    # Load a subset of the dataset\n",
    "    try:\n",
    "        print(\"Loading dataset\")\n",
    "        train_dataset = JetDataset(\"../data/val/val_20_30.h5\", subset_size = 1000)  # Use only 1000 samples    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "    print(\"Creating DataLoader\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # Initialize model\n",
    "    print(\"Initializing model\")\n",
    "    model = IJEPA(input_dim=240, embed_dim=512, depth=12, num_heads=8, mlp_ratio=4.0, dropout=0.1)\n",
    "    # model = IJEPA(input_dim=240, embed_dim=512, depth=16, num_heads=8, mlp_ratio=4.0, dropout=0.1).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.04)\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 10\n",
    "    train_losses = []\n",
    "    \n",
    "    print(f\"Starting training for {num_epochs} epochs\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True, position=0)\n",
    "    \n",
    "        for step, (features, subjets, subjet_masks, particle_masks) in enumerate(train_loader):\n",
    "            features = features.to(device)\n",
    "            subjets = subjets.to(device)\n",
    "            subjet_masks = subjet_masks.to(device)\n",
    "            particle_masks = particle_masks.to(device)\n",
    "            \n",
    "            loss = train_step(model, subjets, subjet_masks, particle_masks, optimizer, device, step)\n",
    "            total_loss += loss\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss)\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(f\"\\nEpoch {epoch+1}, Step {step}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        progress_bar.close()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed\")\n",
    "\n",
    "    # Visualize training loss\n",
    "    print(\"Visualizing training loss\")\n",
    "    visualize_training_loss(train_losses)\n",
    "\n",
    "    print(\"Saving model\")\n",
    "    torch.save(model.state_dict(), 'ijepa_model.pth')\n",
    "\n",
    "    print(\"Model saved. Starting evaluation.\")\n",
    "\n",
    "    # Visualize a sample prediction after training\n",
    "    visualize_sample_prediction(train_loader, model, device, step=num_epochs)\n",
    "\n",
    "    print(\"Evaluation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082464f-9395-4fe5-9771-151e42e201f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e9cb1-2fb1-41c5-8051-9b197ea57751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4547547-20de-433a-a20e-8b0abbc39675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
